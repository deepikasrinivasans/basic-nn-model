{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "import gspread\n",
        "import pandas as pd\n",
        "from google.auth import default\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Authenticate and access the Google Sheets data\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "worksheet = gc.open('Mydata').sheet1\n",
        "data = worksheet.get_all_values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the data into a DataFrame and process it\n",
        "dataset1 = pd.DataFrame(data[1:], columns=data[0])\n",
        "dataset1 = dataset1.astype({'x': 'float', 'y': 'float'})\n",
        "dataset1.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate features and labels\n",
        "X = dataset1[['x']].values\n",
        "Y = dataset1[['y']].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=33)\n",
        "\n",
        "# Scale the data\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train1 = scaler.transform(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the neural network model\n",
        "ai_brain = Sequential([\n",
        "    Dense(8, activation='relu', input_shape=[1]),\n",
        "    Dense(10, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "ai_brain.compile(optimizer='rmsprop', loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "ai_brain.fit(X_train1, y_train.astype(np.float32), epochs=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the loss\n",
        "loss_df = pd.DataFrame(ai_brain.history.history)\n",
        "loss_df.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "X_test1 = scaler.transform(X_test)\n",
        "ai_brain.evaluate(X_test1, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make a prediction\n",
        "X_n1 = [[19]]\n",
        "X_n1_1 = scaler.transform(X_n1)\n",
        "ai_brain.predict(X_n1_1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
